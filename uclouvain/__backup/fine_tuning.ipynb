{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0693aaa9774cb287eea673738a7591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login(new_session=True, write_permission=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "WHERE = \"rag_ucl\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpt = \"xaviergillard/rag_ucl\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpt)\n",
    "model = AutoModelForMaskedLM.from_pretrained(checkpt, torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad92d7cd18d4a4097fbc7fd6b297a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/27423 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "### PREPARE DATASET ####\n",
    "dataset = pd.read_csv(\"corpus_pdf.csv\").dropna()\n",
    "\n",
    "input_ids = []\n",
    "attention_mask = []\n",
    "special_mask = []\n",
    "for row in dataset.itertuples():\n",
    "    text = row.text\n",
    "    if text:\n",
    "        tokenized = tokenizer(\n",
    "            row.text,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=256,\n",
    "            pad_to_multiple_of=256,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_special_tokens_mask=True,\n",
    "            stride=50,\n",
    "        )\n",
    "        input_ids.append(tokenized[\"input_ids\"])\n",
    "        attention_mask.append(tokenized[\"attention_mask\"])\n",
    "        special_mask.append(tokenized[\"special_tokens_mask\"])\n",
    "\n",
    "\n",
    "input_ids = np.concatenate(input_ids)\n",
    "attention_mask = np.concatenate(attention_mask)\n",
    "special_mask = np.concatenate(special_mask)\n",
    "\n",
    "dst_train = pd.DataFrame(\n",
    "    {\"input_ids\": list(input_ids), \"attention_mask\": list(attention_mask), \"special_tokens_mask\": list(special_mask)},\n",
    ")\n",
    "dst_train.to_parquet(\"./tokenized_rag.parquet\", compression=\"gzip\")\n",
    "dst_train = Dataset.from_pandas(dst_train)\n",
    "dst_train.save_to_disk(\"saved_to_disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'special_tokens_mask'],\n",
       "    num_rows: 27423\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dst_train = load_from_disk(\"saved_to_disk\")\n",
    "dst_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7f889b1e094e23b07a627ae71444f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10284 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5249, 'grad_norm': 6.4557785987854, 'learning_rate': 4.756903928432517e-05, 'epoch': 0.15}\n",
      "{'loss': 0.5047, 'grad_norm': 5.638826370239258, 'learning_rate': 4.513807856865033e-05, 'epoch': 0.29}\n",
      "{'loss': 0.503, 'grad_norm': 5.803164958953857, 'learning_rate': 4.2707117852975496e-05, 'epoch': 0.44}\n",
      "{'loss': 0.4843, 'grad_norm': 5.101504325866699, 'learning_rate': 4.027615713730066e-05, 'epoch': 0.58}\n",
      "{'loss': 0.4745, 'grad_norm': 4.502727508544922, 'learning_rate': 3.7845196421625825e-05, 'epoch': 0.73}\n",
      "{'loss': 0.472, 'grad_norm': 6.616970539093018, 'learning_rate': 3.541423570595099e-05, 'epoch': 0.88}\n",
      "{'loss': 0.4777, 'grad_norm': 4.662632942199707, 'learning_rate': 3.298327499027616e-05, 'epoch': 1.02}\n",
      "{'loss': 0.4613, 'grad_norm': 4.002581596374512, 'learning_rate': 3.0552314274601326e-05, 'epoch': 1.17}\n",
      "{'loss': 0.4629, 'grad_norm': 5.761693477630615, 'learning_rate': 2.8121353558926487e-05, 'epoch': 1.31}\n",
      "{'loss': 0.4898, 'grad_norm': 5.485171318054199, 'learning_rate': 2.5690392843251655e-05, 'epoch': 1.46}\n",
      "{'loss': 0.5078, 'grad_norm': 5.314266204833984, 'learning_rate': 2.325943212757682e-05, 'epoch': 1.6}\n",
      "{'loss': 0.5074, 'grad_norm': 6.500685214996338, 'learning_rate': 2.0828471411901985e-05, 'epoch': 1.75}\n",
      "{'loss': 0.5187, 'grad_norm': 5.770079135894775, 'learning_rate': 1.839751069622715e-05, 'epoch': 1.9}\n",
      "{'loss': 0.5568, 'grad_norm': 6.1229329109191895, 'learning_rate': 1.5966549980552314e-05, 'epoch': 2.04}\n",
      "{'loss': 0.5702, 'grad_norm': 6.651785850524902, 'learning_rate': 1.353558926487748e-05, 'epoch': 2.19}\n",
      "{'loss': 0.6941, 'grad_norm': 6.980329513549805, 'learning_rate': 1.1104628549202645e-05, 'epoch': 2.33}\n",
      "{'loss': 0.7991, 'grad_norm': 8.162923812866211, 'learning_rate': 8.673667833527811e-06, 'epoch': 2.48}\n",
      "{'loss': 0.8158, 'grad_norm': 6.612455368041992, 'learning_rate': 6.2427071178529756e-06, 'epoch': 2.63}\n",
      "{'loss': 0.8507, 'grad_norm': 6.006669521331787, 'learning_rate': 3.811746402178141e-06, 'epoch': 2.77}\n",
      "{'loss': 0.8371, 'grad_norm': 7.737505912780762, 'learning_rate': 1.3807856865033063e-06, 'epoch': 2.92}\n",
      "{'train_runtime': 3129.6915, 'train_samples_per_second': 26.287, 'train_steps_per_second': 3.286, 'train_loss': 0.5830961232610085, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10284, training_loss=0.5830961232610085, metrics={'train_runtime': 3129.6915, 'train_samples_per_second': 26.287, 'train_steps_per_second': 3.286, 'total_flos': 1.0827276285247488e+16, 'train_loss': 0.5830961232610085, 'epoch': 3.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    overwrite_output_dir=True,\n",
    "    output_dir=WHERE,\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=\"xaviergillard/rag_ucl\",  # \"xaviergillard/rag_ucl__based_on_xlmroberta\",\n",
    "    hub_strategy=\"checkpoint\",\n",
    "    # faster training\n",
    "    max_grad_norm=8.0,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dst_train,\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a14f4f4dab406ab73371e949cbd349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1497, 'grad_norm': 7.78125, 'learning_rate': 4.70828471411902e-05, 'epoch': 0.29}\n",
      "{'loss': 3.135, 'grad_norm': 7.65625, 'learning_rate': 4.41656942823804e-05, 'epoch': 0.58}\n",
      "{'loss': 3.0942, 'grad_norm': 7.65625, 'learning_rate': 4.12485414235706e-05, 'epoch': 0.88}\n",
      "{'loss': 3.0851, 'grad_norm': 7.34375, 'learning_rate': 3.8331388564760794e-05, 'epoch': 1.17}\n",
      "{'loss': 3.0661, 'grad_norm': 8.125, 'learning_rate': 3.541423570595099e-05, 'epoch': 1.46}\n",
      "{'loss': 3.0699, 'grad_norm': 7.59375, 'learning_rate': 3.249708284714119e-05, 'epoch': 1.75}\n",
      "{'loss': 3.0466, 'grad_norm': 8.25, 'learning_rate': 2.957992998833139e-05, 'epoch': 2.04}\n",
      "{'loss': 3.0444, 'grad_norm': 6.9375, 'learning_rate': 2.666277712952159e-05, 'epoch': 2.33}\n",
      "{'loss': 3.057, 'grad_norm': 8.3125, 'learning_rate': 2.3745624270711785e-05, 'epoch': 2.63}\n",
      "{'loss': 3.0562, 'grad_norm': 7.5, 'learning_rate': 2.0828471411901985e-05, 'epoch': 2.92}\n",
      "{'loss': 3.0397, 'grad_norm': 7.8125, 'learning_rate': 1.791131855309218e-05, 'epoch': 3.21}\n",
      "{'loss': 3.0611, 'grad_norm': 8.1875, 'learning_rate': 1.499416569428238e-05, 'epoch': 3.5}\n",
      "{'loss': 3.0401, 'grad_norm': 7.90625, 'learning_rate': 1.2077012835472578e-05, 'epoch': 3.79}\n",
      "{'loss': 3.0473, 'grad_norm': 7.84375, 'learning_rate': 9.159859976662778e-06, 'epoch': 4.08}\n",
      "{'loss': 3.0514, 'grad_norm': 7.59375, 'learning_rate': 6.2427071178529756e-06, 'epoch': 4.38}\n",
      "{'loss': 3.0406, 'grad_norm': 7.90625, 'learning_rate': 3.325554259043174e-06, 'epoch': 4.67}\n",
      "{'loss': 3.0322, 'grad_norm': 7.9375, 'learning_rate': 4.084014002333722e-07, 'epoch': 4.96}\n",
      "{'train_runtime': 2418.4897, 'train_samples_per_second': 56.694, 'train_steps_per_second': 3.544, 'train_loss': 3.065519253208868, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8570, training_loss=3.065519253208868, metrics={'train_runtime': 2418.4897, 'train_samples_per_second': 56.694, 'train_steps_per_second': 3.544, 'total_flos': 1.804546047541248e+16, 'train_loss': 3.065519253208868, 'epoch': 5.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's make another round of it.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm still not happy with it ... (maybe that loading the model in f32 would be better)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-ucl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
